{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight component exercise\n",
    "\n",
    "The goal of this exerices is to build a pipeline with two components built using ```kfp.components.func_to_container_op```.\n",
    "\n",
    "The first one, **WRITE**,\n",
    "- takes as input a string and a GCS path\n",
    "- writes the input string to the GCS path\n",
    "- outputs the GCS path .\n",
    "\n",
    "The second one, **READ**,\n",
    "- takes as input a GCS path\n",
    "- reads its content and print it.\n",
    "\n",
    "## Import kfp modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "from kfp import Client as KfpClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component **WRITE**\n",
    "\n",
    "1. The easiest way to write directly to GCS is to use ```tf.io.gfile.GFile```. The price to pay is that the image of your container is quite heavy.\n",
    "2. The third hint is that the function can be run if the all the dependencies are installed\n",
    "\n",
    "### Start with the function ```write_to_gcs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_gcs(content: str, output_path: str) -> str:\n",
    "    \"\"\"Simple function to write content to file in GCS\"\"\"\n",
    "    from tensorflow.io import gfile\n",
    "    with gfile.GFile(output_path, 'w') as f_out:\n",
    "        f_out.write(content)\n",
    "        \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the op ```write_to_gcs_op```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_gcs_op = comp.func_to_container_op(write_to_gcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component **READ**\n",
    "\n",
    "### Start with the function ```read_from_gcs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_gcs(input_path: str) -> None:\n",
    "    \"\"\"Simple function to read content from a file on GCS\"\"\"\n",
    "    from tensorflow.io import gfile\n",
    "    with gfile.GFile(input_path, 'r') as f_in:\n",
    "        for line in f_in.readlines():\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the op ```read_from_gcs_op```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_from_gcs_op = comp.func_to_container_op(read_from_gcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crate the pipeline write_and_read\n",
    "\n",
    "- Use your user name in the pipeline name to make it unique\n",
    "- Remember to apply the gcp secret ```'user-gcp-sa'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name='Read and write',\n",
    "    description='A pipeline that writes to a file in GCS and reads back the content'\n",
    ")\n",
    "def write_and_read(\n",
    "    content: str='',\n",
    "    gcs_path: dsl.types.GCSPath=''\n",
    "):\n",
    "    write_to_gcs_task = write_to_gcs_op(\n",
    "        content=content, output_path=gcs_path).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    write_to_gcs_task.set_display_name('Write file to GCS')\n",
    "    \n",
    "    read_from_gcs_task = read_from_gcs_op(\n",
    "        write_to_gcs_task.output).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "    read_from_gcs_task.set_display_name('Read from file on GCS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and connect the client\n",
    "\n",
    "If running outside of the cluster with Kubeflow, set `GOOGLE_APPLICATION_CREDENTIALS` for dealing with authorisation. The service account needs to have the role `IAP-secured Web App User`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '' # path to the json file of the service account used to log in: it need to have role IAP-secured Web App User\n",
    "# HOST = '' # url of the cluster e.g. https://demo-kubeflow.endpoints.lf-ml-demo.cloud.goog/pipeline\n",
    "# CLIENT_ID = '' # The client ID used by Identity-Aware Proxy\n",
    "# NAMESPACE = '' # user namespace e.g. https://demo-kubeflow.endpoints.lf-ml-demo.cloud.goog/pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = KfpClient(\n",
    "# we are running into the same Kubeflow so we do not need to do anything\n",
    "#     host=HOST,\n",
    "#     client_id=CLIENT_ID,\n",
    "#     namespace=NAMESPACE  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "Run the pipeline using the method ```create_run_from_pipeline_func``` of the class ```kfp.Client```.\n",
    "\n",
    "To make unique your GCS path use the template ```{{workflow.uid}}``` and ```{{pod.name}}```.\n",
    "1. Why are we doing it?\n",
    "2. Why can we do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_run_from_pipeline_func(\n",
    "    pipeline_func=write_and_read,\n",
    "    arguments={'content': '0\\n1\\n', \n",
    "               'gcs_path': 'gs://lf-ml-demo-eu-w1/{{workflow.uid}}/{{pod.name}}/data'},\n",
    "    experiment_name='01_single_write_and_read',\n",
    "    run_name='001'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copyright 2019 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
